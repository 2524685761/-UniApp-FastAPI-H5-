项目名称：基于多源信息融合情感识别的国家通用语智能学习系统

项目类型：毕业设计 / 全栈工程项目（前后端分离 + 语音交互 + AI 能力集成）

问题/需求：
1) 偏远地区国家通用语学习存在师资不足、缺少一对一纠音与即时反馈的问题。
2) 传统练习方式难以持续激励，学习过程中的困惑/挫败等情绪缺少及时引导。
3) 需要一个可在本地或局域网运行的原型系统，降低网络依赖与隐私风险。

解决方案：
1) 前端使用 Uni-app 实现跨端语音交互（录音、上传、播放、反馈展示）。
2) 后端使用 Python FastAPI 提供 REST API，完成录音接收、音频处理与结果返回。
3) 集成 FunASR 完成语音识别（ASR），输出识别文本用于对照与纠错提示。
4) 发音评估采用可解释的工程指标（时长、音量、停顿比例、文本一致性、语速等），并预留接入专业评分服务的扩展口。
5) 学习状态/情绪推断采用“语音韵律特征 + 学习行为（得分、尝试次数）”的多源信息融合规则引擎，并在负面状态下触发自适应策略（增加示范、放慢节奏、提示重试/跳过/休息等）。
6) 录音数据默认不长期落盘，仅在调试开关开启时保存，降低敏感数据存储风险。

本人角色与职责：本人全程独立负责（需求分析、方案设计、前后端开发、接口设计、音频处理、ASR/评估/情感推断与自适应逻辑实现、联调测试与可运行交付）。

参与时间段：2026年09月—2026年12月

项目成果/：
1) 交付可运行的原型系统：Uni-app 前端 + FastAPI 后端 + SQLite 数据存储。
2) 实现录音练习闭环：示范音 → 录音上传 → ASR/评分/情感推断 → 反馈展示与引导下一步。
3) 输出结构化结果：分数、问题点、识别文本、学习状态/鼓励语、自适应策略参数。
4) 支持本地/局域网部署与调试，具备可扩展的 AI 能力接入路径（情感模型/专业评分服务等）。

